{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "tce5YIDRGH0v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d20479a-7e80-4411-8dc1-e29b05641b7f"
      },
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, when\n",
        "from pyspark.sql.types import FloatType\n",
        "from pyspark.ml.feature import VectorAssembler, StandardScaler, PCA\n",
        "import pandas as pd\n",
        "\n",
        "# Initialize Spark\n",
        "spark = SparkSession.builder.appName(\"KDDCupAnomalyDetection\").getOrCreate()\n",
        "\n",
        "# Load column names\n",
        "with open('/content/kddcup.names.txt', 'r') as f:\n",
        "    col_names_raw = f.readlines()\n",
        "col_names_cleaned = [line.split(':')[0].strip() for line in col_names_raw if ':' in line]\n",
        "col_names_cleaned.append('result')\n",
        "\n",
        "# Load dataset\n",
        "df = spark.read.csv('/content/kddcup.data.corrected', header=False, inferSchema=True)\n",
        "df = df.toDF(*col_names_cleaned)\n",
        "\n",
        "# Filter http + normal\n",
        "df_http = df.filter(col('service') == 'http')\n",
        "df_http_normal = df_http.filter(col('result') == 'normal.')\n",
        "\n",
        "# Drop non-numerical/unwanted cols\n",
        "cols_to_drop = ['protocol_type', 'service', 'flag', 'land', 'logged_in',\n",
        "                'is_host_login', 'is_guest_login', 'result',\n",
        "                'wrong_fragment', 'urgent',\n",
        "                'su_attempted', 'num_file_creations', 'num_outbound_cmds']\n",
        "df_http_normal = df_http_normal.drop(*cols_to_drop)\n",
        "\n",
        "# Cast all to float\n",
        "for c in df_http_normal.columns:\n",
        "    df_http_normal = df_http_normal.withColumn(c, col(c).cast(FloatType()))\n",
        "\n",
        "# 5. Train/Test split (20% test, 80% train)\n",
        "test, train = df_http_normal.randomSplit([0.2, 0.8], seed=42)\n",
        "print(f\"Train count = {train.count()}, Test count = {test.count()}\")\n",
        "# Assemble & scale on TRAIN\n",
        "assembler = VectorAssembler(inputCols=train.columns, outputCol=\"features\")\n",
        "df_features = assembler.transform(df_http_normal)\n",
        "train_feats = assembler.transform(train)\n",
        "scaler     = StandardScaler(inputCol=\"features\", outputCol=\"scaled_features\",\n",
        "                             withMean=True, withStd=True)\n",
        "scaler_model = scaler.fit(train_feats)\n",
        "train_scaled = scaler_model.transform(train_feats)\n",
        "df_scaled = scaler_model.transform(df_features)\n",
        "\n",
        "# PCA on TRAIN\n",
        "k = 14\n",
        "pca = PCA(k=k, inputCol=\"scaled_features\", outputCol=\"pca_features\")\n",
        "pca_model = pca.fit(train_scaled)\n",
        "train_pca = pca_model.transform(train_scaled).select(\"pca_features\")\n",
        "df_pca = pca_model.transform(df_scaled).select(\"pca_features\")\n",
        "pdf = df_pca.toPandas()\n",
        "pca_cols = ['PCA_' + str(i) for i in range(k)]\n",
        "pdf_pca = pd.DataFrame(pdf['pca_features'].tolist(), columns=pca_cols)\n",
        "pdf_pca.head()\n",
        "pdf_train = train_pca.toPandas()\n",
        "pdf_train_pca = pd.DataFrame(\n",
        "    pdf_train['pca_features'].tolist(), columns=pca_cols\n",
        ")\n",
        "\n",
        "pca_cols = ['PCA_' + str(i) for i in range(k)]\n",
        "\n",
        "# Sliding Windows\n",
        "import numpy as np\n",
        "import tqdm\n",
        "\n",
        "def get_windows(df, window_size=10, stride=10):\n",
        "    windows = []\n",
        "    for i in tqdm.tqdm(range(0, len(df) - window_size + 1, stride)):\n",
        "        windows.append(df.iloc[i:i + window_size].to_numpy())\n",
        "    return np.array(windows)\n",
        "\n",
        "window_size = 10\n",
        "stride = 10\n",
        "windows_arr = get_windows(pdf_train_pca, window_size, stride)\n",
        "\n",
        "# Shuffle\n",
        "np.random.shuffle(windows_arr)\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train count = 111358, Test count = 28115\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11135/11135 [00:00<00:00, 63867.00it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import LSTM, TimeDistributed, Dense, RepeatVector\n",
        "from tensorflow.keras.models import Sequential\n",
        "import tensorflow.keras.backend as K\n",
        "\n",
        "K.clear_session()\n",
        "\n",
        "# Encoder\n",
        "encoder = Sequential([\n",
        "    LSTM(80, return_sequences=True, activation='selu', input_shape=(window_size, k)),\n",
        "    LSTM(50, return_sequences=True, activation='selu'),\n",
        "    LSTM(20, activation='selu'),\n",
        "], name='encoder')\n",
        "\n",
        "# Decoder\n",
        "decoder = Sequential([\n",
        "    RepeatVector(window_size),\n",
        "    LSTM(50, return_sequences=True, activation='selu'),\n",
        "    LSTM(80, return_sequences=True, activation='selu'),\n",
        "    TimeDistributed(Dense(k, activation='linear'))\n",
        "], name='decoder')\n",
        "\n",
        "# Autoencoder\n",
        "autoencoder = Sequential([encoder, decoder], name='autoencoder')\n",
        "autoencoder.compile(optimizer='adam', loss=tf.keras.losses.Huber(100.))\n",
        "autoencoder.fit(windows_arr, windows_arr[:, :, ::-1], epochs=5, batch_size=64, validation_split=0.2)\n",
        "\n",
        "# Save Model\n",
        "autoencoder.save(\"autoencoder.h5\")\n"
      ],
      "metadata": {
        "id": "uNsPBH77zngi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e16761e4-8023-4cb6-b9d9-3e542f01250c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 54ms/step - loss: 0.7974 - val_loss: 0.5839\n",
            "Epoch 2/5\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 51ms/step - loss: 0.6491 - val_loss: 0.5707\n",
            "Epoch 3/5\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 59ms/step - loss: 0.5706 - val_loss: 0.5643\n",
            "Epoch 4/5\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 58ms/step - loss: 0.7109 - val_loss: 0.5466\n",
            "Epoch 5/5\n",
            "\u001b[1m140/140\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 47ms/step - loss: 0.4508 - val_loss: 0.5405\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model(autoencoder)\n",
        "converter.target_spec.supported_ops = [\n",
        "    tf.lite.OpsSet.TFLITE_BUILTINS,\n",
        "    tf.lite.OpsSet.SELECT_TF_OPS  # Enable Select TF ops\n",
        "]\n",
        "converter._experimental_lower_tensor_list_ops = False  # Avoid lowering TensorList ops\n",
        "converter.experimental_enable_resource_variables = True  # Enable resource variable support\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "\n",
        "\n",
        "# Save TFLite model\n",
        "with open(\"autoencoder.tflite\", \"wb\") as f:\n",
        "    f.write(tflite_model)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1oD_ijyH7c67",
        "outputId": "6d655c24-c0f2-4eb4-ff62-775025625e7f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved artifact at '/tmp/tmprga22hu5'. The following endpoints are available:\n",
            "\n",
            "* Endpoint 'serve'\n",
            "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 10, 14), dtype=tf.float32, name='keras_tensor_4')\n",
            "Output Type:\n",
            "  TensorSpec(shape=(None, 10, 14), dtype=tf.float32, name=None)\n",
            "Captures:\n",
            "  138684717502864: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138684717511504: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138684717514576: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138684717510544: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138684717511312: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138684717514384: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138684717513616: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138684717513424: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138684717510928: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138684715516752: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138684715519248: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138684715520016: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138684715520208: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138684715521168: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138684715521744: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138684715521936: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  138684715522896: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tflite-runtime\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TCq1yNDI7foM",
        "outputId": "c39d4ae1-96a2-4f39-de37-acd70354dc3c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tflite-runtime\n",
            "  Downloading tflite_runtime-2.14.0-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from tflite-runtime) (2.0.2)\n",
            "Downloading tflite_runtime-2.14.0-cp311-cp311-manylinux2014_x86_64.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tflite-runtime\n",
            "Successfully installed tflite-runtime-2.14.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy<2\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MjxKmdrPBzJn",
        "outputId": "874d56b1-461e-428c-b8a5-7e39676fadba"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: 2: No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "interpreter = tf.lite.Interpreter(model_path=\"autoencoder.tflite\")\n",
        "\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "# Get input/output details\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "\n",
        "# Function to predict a single sample\n",
        "def predict_tflite(sample_batch):\n",
        "    predictions = []\n",
        "    for i in range(sample_batch.shape[0]):\n",
        "        sample = np.expand_dims(sample_batch[i], axis=0).astype(np.float32)\n",
        "        interpreter.set_tensor(input_details[0]['index'], sample)\n",
        "        interpreter.invoke()\n",
        "        output = interpreter.get_tensor(output_details[0]['index'])\n",
        "        predictions.append(output[0])\n",
        "    return np.array(predictions)\n",
        "\n",
        "# Load test data\n",
        "test_df = spark.read.csv('/content/kddcup.data.corrected', header=False, inferSchema=True)\n",
        "test_df = test_df.toDF(*col_names_cleaned)\n",
        "test_df_http = test_df.filter(col('service') == 'http')\n",
        "test_df_http = test_df_http.withColumn(\"anomaly_indicator\", when(col('result') == 'normal.', 0).otherwise(1))\n",
        "test_df_http = test_df_http.drop(*cols_to_drop)\n",
        "\n",
        "# Cast all test columns\n",
        "for c in test_df_http.columns:\n",
        "    if c != \"anomaly_indicator\":\n",
        "        test_df_http = test_df_http.withColumn(c, col(c).cast(FloatType()))\n",
        "\n",
        "assembler_test = VectorAssembler(inputCols=[c for c in test_df_http.columns if c != \"anomaly_indicator\"], outputCol=\"features\")\n",
        "test_df_features = assembler_test.transform(test_df_http)\n",
        "test_df_scaled = scaler_model.transform(test_df_features)\n",
        "test_df_pca = pca_model.transform(test_df_scaled).select(\"pca_features\")\n",
        "\n",
        "pdf_test = test_df_pca.toPandas()\n",
        "pdf_test_pca = pd.DataFrame(pdf_test['pca_features'].tolist(), columns=pca_cols)\n",
        "\n",
        "test_windows = get_windows(pdf_test_pca, window_size=10, stride=10)\n",
        "tflite_preds = predict_tflite(test_windows)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hy21JGde7h6a",
        "outputId": "7fe5a96e-f24d-47fa-af95-c0254050fc84"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 22369/22369 [00:00<00:00, 30234.30it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate reconstruction errors\n",
        "def get_recon_errors(true_windows, pred_windows):\n",
        "    recon_errors = []\n",
        "    for i in range(true_windows.shape[0]):\n",
        "        diff = true_windows[i] - pred_windows[i]\n",
        "        error = np.mean(np.linalg.norm(diff, axis=1))\n",
        "        recon_errors.append(error)\n",
        "    return np.array(recon_errors).reshape(-1, 1)\n",
        "\n",
        "recon_errors = get_recon_errors(test_windows, tflite_preds)\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "mm_scaler = MinMaxScaler()\n",
        "anomaly_scores = mm_scaler.fit_transform(recon_errors).flatten()\n",
        "\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score\n",
        "\n",
        "test_labels_series = test_df_http.select(\"anomaly_indicator\").toPandas()\n",
        "test_labels_arr = test_labels_series.values.flatten()\n",
        "test_window_labels = [1 if np.sum(test_labels_arr[i:i+window_size]) > 0 else 0\n",
        "                      for i in range(0, len(test_labels_arr) - window_size + 1, stride)]\n",
        "\n",
        "thresholds = np.linspace(0.0, 1.0, num=50)\n",
        "anomaly_combinations = [(anomaly_scores > thr).astype(int) for thr in thresholds]\n",
        "f1_scores = [f1_score(test_window_labels, pred) for pred in anomaly_combinations]\n",
        "max_f1_score = np.max(f1_scores)\n",
        "best_threshold = thresholds[f1_scores.index(max_f1_score)]\n",
        "print('Best threshold =', best_threshold)\n",
        "\n",
        "anomaly_indicator = (anomaly_scores > best_threshold).astype(int)\n",
        "print('Precision:', precision_score(test_window_labels, anomaly_indicator))\n",
        "print('Recall:', recall_score(test_window_labels, anomaly_indicator))\n",
        "print('F1:', f1_score(test_window_labels, anomaly_indicator))\n",
        "print('Accuracy:', accuracy_score(test_window_labels, anomaly_indicator))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tZIlL9K97pxN",
        "outputId": "a67e3741-8a00-4276-d001-268cd26c9324"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best threshold = 0.3877551020408163\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1: 1.0\n",
            "Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SOiTsEh53Egv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Uy3uE4y83EZ9"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Dr46Lz9B3EVR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "elfK87Zx3ENv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/kddcup.names.txt', 'r') as f:\n",
        "    col_names_raw = f.readlines()\n",
        "col_names_cleaned = [line.split(':')[0].strip() for line in col_names_raw if ':' in line]\n",
        "col_names_cleaned.append('result')\n",
        "\n",
        "# Load dataset\n",
        "df = spark.read.csv('/content/kddcup.data.corrected', header=False, inferSchema=True)\n",
        "df = df.toDF(*col_names_cleaned)"
      ],
      "metadata": {
        "id": "6ji919A6GEsa"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cGxf7SRMGFKL",
        "outputId": "c4e2c23e-f5a3-43d3-c477-7312b8a7b17b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[duration: int, protocol_type: string, service: string, flag: string, src_bytes: int, dst_bytes: int, land: int, wrong_fragment: int, urgent: int, hot: int, num_failed_logins: int, logged_in: int, num_compromised: int, root_shell: int, su_attempted: int, num_root: int, num_file_creations: int, num_shells: int, num_access_files: int, num_outbound_cmds: int, is_host_login: int, is_guest_login: int, count: int, srv_count: int, serror_rate: double, srv_serror_rate: double, rerror_rate: double, srv_rerror_rate: double, same_srv_rate: double, diff_srv_rate: double, srv_diff_host_rate: double, dst_host_count: int, dst_host_srv_count: int, dst_host_same_srv_rate: double, dst_host_diff_srv_rate: double, dst_host_same_src_port_rate: double, dst_host_srv_diff_host_rate: double, dst_host_serror_rate: double, dst_host_srv_serror_rate: double, dst_host_rerror_rate: double, dst_host_srv_rerror_rate: double, result: string]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.write.csv(\"/content/cleaned_data_spark\", header=True)\n",
        "\n"
      ],
      "metadata": {
        "id": "0NJls0mDGaao"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Zip the folder\n",
        "!zip -r /content/cleaned_data_spark.zip /content/cleaned_data_spark\n",
        "\n",
        "# Download\n",
        "from google.colab import files\n",
        "files.download(\"/content/cleaned_data_spark.zip\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "id": "LHHd44woGhAf",
        "outputId": "ef82823a-946a-4214-bcfb-036b9808b5c8"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/cleaned_data_spark/ (stored 0%)\n",
            "  adding: content/cleaned_data_spark/_SUCCESS (stored 0%)\n",
            "  adding: content/cleaned_data_spark/part-00000-471da543-a3aa-49fd-b157-e3f2493d3242-c000.csv (deflated 94%)\n",
            "  adding: content/cleaned_data_spark/._SUCCESS.crc (stored 0%)\n",
            "  adding: content/cleaned_data_spark/.part-00000-471da543-a3aa-49fd-b157-e3f2493d3242-c000.csv.crc (deflated 15%)\n",
            "  adding: content/cleaned_data_spark/part-00001-471da543-a3aa-49fd-b157-e3f2493d3242-c000.csv (deflated 93%)\n",
            "  adding: content/cleaned_data_spark/.part-00001-471da543-a3aa-49fd-b157-e3f2493d3242-c000.csv.crc (deflated 0%)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_e130ea39-62f3-43db-a65e-d2711fc05c31\", \"cleaned_data_spark.zip\", 3491845)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Create a DataFrame to store results\n",
        "results_df = pd.DataFrame({\n",
        "    'Anomaly_Score': anomaly_scores,\n",
        "    'Predicted_Label': anomaly_indicator,\n",
        "    'True_Label': test_window_labels\n",
        "})\n",
        "\n",
        "# Save to CSV\n",
        "results_df.to_csv(\"anomaly_detection_results.csv\", index=False)\n",
        "print(\"Results saved to 'anomaly_detection_results.csv'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yM6DRzXSHaPc",
        "outputId": "f2a89037-c443-4188-cdb5-f3a200b08c6a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results saved to 'anomaly_detection_results.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results_df[\"Reconstruction_Error\"] = recon_errors.flatten()\n"
      ],
      "metadata": {
        "id": "WEN0mDGwJC6r"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results_df.to_csv(\"anomaly_detection_results.csv\", index=False)"
      ],
      "metadata": {
        "id": "cDnUAeSKJFsN"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "import json\n",
        "import os\n",
        "\n",
        "# Make a folder to store metadata\n",
        "os.makedirs(\"model_metadata\", exist_ok=True)\n",
        "\n",
        "# Save Spark StandardScaler model\n",
        "scaler_model.save(\"model_metadata/scaler_model\")\n",
        "\n",
        "# Save Spark PCA model\n",
        "pca_model.save(\"model_metadata/pca_model\")\n",
        "\n",
        "# Save column names used for features\n",
        "with open(\"model_metadata/feature_columns.json\", \"w\") as f:\n",
        "    json.dump(df_http_normal.columns, f)\n",
        "\n",
        "# Save PCA column names (for Pandas)\n",
        "with open(\"model_metadata/pca_columns.json\", \"w\") as f:\n",
        "    json.dump(pca_cols, f)\n",
        "\n",
        "# Save window size and stride\n",
        "params = {\n",
        "    \"window_size\": window_size,\n",
        "    \"stride\": stride\n",
        "}\n",
        "with open(\"model_metadata/preprocessing_params.json\", \"w\") as f:\n",
        "    json.dump(params, f)\n"
      ],
      "metadata": {
        "id": "b-8EdE80Kyi9"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/kddcup.names.txt', 'r') as f:\n",
        "    col_names_raw = f.readlines()\n",
        "col_names_cleaned = [line.split(':')[0].strip() for line in col_names_raw if ':' in line]\n",
        "col_names_cleaned.append('result')"
      ],
      "metadata": {
        "id": "Sk-BNoCouTXJ"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "col_names_cleaned"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BYoCVDKzuUFK",
        "outputId": "2a556d90-ee98-4dcf-b793-5df43a0fb92d"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['duration',\n",
              " 'protocol_type',\n",
              " 'service',\n",
              " 'flag',\n",
              " 'src_bytes',\n",
              " 'dst_bytes',\n",
              " 'land',\n",
              " 'wrong_fragment',\n",
              " 'urgent',\n",
              " 'hot',\n",
              " 'num_failed_logins',\n",
              " 'logged_in',\n",
              " 'num_compromised',\n",
              " 'root_shell',\n",
              " 'su_attempted',\n",
              " 'num_root',\n",
              " 'num_file_creations',\n",
              " 'num_shells',\n",
              " 'num_access_files',\n",
              " 'num_outbound_cmds',\n",
              " 'is_host_login',\n",
              " 'is_guest_login',\n",
              " 'count',\n",
              " 'srv_count',\n",
              " 'serror_rate',\n",
              " 'srv_serror_rate',\n",
              " 'rerror_rate',\n",
              " 'srv_rerror_rate',\n",
              " 'same_srv_rate',\n",
              " 'diff_srv_rate',\n",
              " 'srv_diff_host_rate',\n",
              " 'dst_host_count',\n",
              " 'dst_host_srv_count',\n",
              " 'dst_host_same_srv_rate',\n",
              " 'dst_host_diff_srv_rate',\n",
              " 'dst_host_same_src_port_rate',\n",
              " 'dst_host_srv_diff_host_rate',\n",
              " 'dst_host_serror_rate',\n",
              " 'dst_host_srv_serror_rate',\n",
              " 'dst_host_rerror_rate',\n",
              " 'dst_host_srv_rerror_rate',\n",
              " 'result']"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip \"kddcup.data.corrected.zip\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wrF7CR0FuVhG",
        "outputId": "3ff6291c-d69e-4d86-8e74-3c2d4d373296"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "unzip:  cannot find or open kddcup.data.corrected.zip, kddcup.data.corrected.zip.zip or kddcup.data.corrected.zip.ZIP.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1) Zip the folder\n",
        "!zip -r model_metadata.zip model_metadata\n",
        "\n",
        "# 2) Download the zip to your computer\n",
        "from google.colab import files\n",
        "files.download(\"model_metadata.zip\")\n"
      ],
      "metadata": {
        "id": "wRxRo52jKzoR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468
        },
        "outputId": "7d8ce36d-4a20-451b-c3f4-9c4a772f67fa"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: model_metadata/ (stored 0%)\n",
            "  adding: model_metadata/pca_columns.json (deflated 62%)\n",
            "  adding: model_metadata/scaler_model/ (stored 0%)\n",
            "  adding: model_metadata/scaler_model/data/ (stored 0%)\n",
            "  adding: model_metadata/scaler_model/data/part-00000-036fa528-e5e4-4368-9972-3ab9c37d8492-c000.snappy.parquet (deflated 58%)\n",
            "  adding: model_metadata/scaler_model/data/_SUCCESS (stored 0%)\n",
            "  adding: model_metadata/scaler_model/data/.part-00000-036fa528-e5e4-4368-9972-3ab9c37d8492-c000.snappy.parquet.crc (stored 0%)\n",
            "  adding: model_metadata/scaler_model/data/._SUCCESS.crc (stored 0%)\n",
            "  adding: model_metadata/scaler_model/metadata/ (stored 0%)\n",
            "  adding: model_metadata/scaler_model/metadata/_SUCCESS (stored 0%)\n",
            "  adding: model_metadata/scaler_model/metadata/._SUCCESS.crc (stored 0%)\n",
            "  adding: model_metadata/scaler_model/metadata/.part-00000.crc (stored 0%)\n",
            "  adding: model_metadata/scaler_model/metadata/part-00000 (deflated 43%)\n",
            "  adding: model_metadata/preprocessing_params.json (deflated 9%)\n",
            "  adding: model_metadata/pca_model/ (stored 0%)\n",
            "  adding: model_metadata/pca_model/data/ (stored 0%)\n",
            "  adding: model_metadata/pca_model/data/part-00000-2d140804-cc04-46b3-9121-0cdd7ac33462-c000.snappy.parquet (deflated 35%)\n",
            "  adding: model_metadata/pca_model/data/_SUCCESS (stored 0%)\n",
            "  adding: model_metadata/pca_model/data/.part-00000-2d140804-cc04-46b3-9121-0cdd7ac33462-c000.snappy.parquet.crc (stored 0%)\n",
            "  adding: model_metadata/pca_model/data/._SUCCESS.crc (stored 0%)\n",
            "  adding: model_metadata/pca_model/metadata/ (stored 0%)\n",
            "  adding: model_metadata/pca_model/metadata/_SUCCESS (stored 0%)\n",
            "  adding: model_metadata/pca_model/metadata/._SUCCESS.crc (stored 0%)\n",
            "  adding: model_metadata/pca_model/metadata/.part-00000.crc (stored 0%)\n",
            "  adding: model_metadata/pca_model/metadata/part-00000 (deflated 34%)\n",
            "  adding: model_metadata/feature_columns.json (deflated 69%)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_a4bf9fd8-344c-4f0f-bb18-32898e77b69b\", \"model_metadata.zip\", 12579)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mkyd-MZJLdQR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}